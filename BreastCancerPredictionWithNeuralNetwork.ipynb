{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook we use Google's Tensorflow library to classify the type of the tumor as malignant or benign knowing its characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make NumPy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Normalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "\n",
    "### Reading the data\n",
    "\n",
    "Reading the dataset into a Pandas Dataframe Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"breast-cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the data\n",
    "\n",
    "#### Handling Null Values\n",
    "\n",
    "The dataset has no null values as seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Categorical values\n",
    "\n",
    "The `diagnosis` column is categorical, not numeric. So the next step is to convert it to numeric by replacing 'M' with 1 and 'B' with 0 using `pd.replace`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          1        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          1        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          1        11.42         20.38           77.58      386.1   \n",
       "4  84358402          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.replace(['M', 'B'],\n",
    "             [1, 0], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Outliers\n",
    "\n",
    "Remove outliers that have z score higher than 3 or lower than -3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets\n",
    "\n",
    "Now, split the dataset into a training set and a test set. We will use the test set in the final evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.sample(frac=0.8, random_state=0)\n",
    "test_dataset = data.drop(train_dataset.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split features from labels\n",
    "Separate the target value â€”the diagnosis, also called the labelâ€” from the features. This label is the value that we will train the model to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('diagnosis')\n",
    "test_labels = test_features.pop('diagnosis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 31)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "In the table of statistics it's easy to see how different the ranges of each feature are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>14.038009</td>\n",
       "      <td>3.443339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>19.254352</td>\n",
       "      <td>4.356593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>91.345407</td>\n",
       "      <td>23.756012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoothness_mean</th>\n",
       "      <td>0.096414</td>\n",
       "      <td>0.014029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compactness_mean</th>\n",
       "      <td>0.103311</td>\n",
       "      <td>0.052823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concavity_mean</th>\n",
       "      <td>0.087379</td>\n",
       "      <td>0.080251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean        std\n",
       "radius_mean       14.038009   3.443339\n",
       "texture_mean      19.254352   4.356593\n",
       "perimeter_mean    91.345407  23.756012\n",
       "smoothness_mean    0.096414   0.014029\n",
       "compactness_mean   0.103311   0.052823\n",
       "concavity_mean     0.087379   0.080251"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[['radius_mean', 'texture_mean', 'perimeter_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean']].describe().transpose()[['mean', 'std']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to normalize features that have different ranges.\n",
    "\n",
    "If we skip normalizing the features, the model will still converge (ie: reach the optimum loss), However, normalization makes training much more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normalization layer\n",
    "\n",
    "The tf.keras.layers.Normalization is a clean and simple way to add feature normalization into the model.\n",
    "\n",
    "The first step is to create the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, fit the state of the preprocessing layer to the data by calling Normalization.adapt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.adapt(np.array(train_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the layer is called, it returns the input data, with each feature independently normalized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First example: [[915691.       13.4      20.52     88.64    556.7       0.11      0.15\n",
      "       0.14      0.08      0.21      0.07      0.39      0.93      3.09\n",
      "      33.67      0.01      0.02      0.03      0.01      0.02      0.\n",
      "      16.41     29.66    113.3     844.4       0.16      0.39      0.51\n",
      "       0.21      0.36      0.11]]\n",
      "\n",
      "Normalized: [[-0.23 -0.19  0.29 -0.11 -0.26  1.01  0.83  0.71  0.88  1.09  1.44 -0.04\n",
      "  -0.52  0.13 -0.14 -0.56 -0.15  0.08  0.24 -0.44  0.07  0.06  0.66  0.22\n",
      "  -0.03  1.1   0.88  1.16  1.41  1.08  1.55]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print('First example:', first)\n",
    "    print()\n",
    "    print('Normalized:', normalizer(first).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "### Building the Neural Network Model\n",
    "\n",
    "We first declare the layers of the neural network and their activation functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then config the model with losses and metrics that we want using `model.compile()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then trains the model on the training data for a fixed number of epochs (iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 1s 12ms/step - loss: 0.6924 - accuracy: 0.5604 - val_loss: 0.6255 - val_accuracy: 0.7544\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.8703 - val_loss: 0.5255 - val_accuracy: 0.8947\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.9209 - val_loss: 0.4472 - val_accuracy: 0.9298\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4189 - accuracy: 0.9297 - val_loss: 0.3790 - val_accuracy: 0.9298\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.9253 - val_loss: 0.3204 - val_accuracy: 0.9298\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.9319 - val_loss: 0.2725 - val_accuracy: 0.9474\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.9341 - val_loss: 0.2336 - val_accuracy: 0.9474\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2271 - accuracy: 0.9407 - val_loss: 0.2013 - val_accuracy: 0.9737\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9407 - val_loss: 0.1731 - val_accuracy: 0.9912\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1739 - accuracy: 0.9516 - val_loss: 0.1520 - val_accuracy: 0.9912\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9538 - val_loss: 0.1335 - val_accuracy: 0.9912\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9626 - val_loss: 0.1195 - val_accuracy: 0.9912\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9648 - val_loss: 0.1069 - val_accuracy: 0.9825\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9692 - val_loss: 0.0966 - val_accuracy: 0.9825\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9714 - val_loss: 0.0886 - val_accuracy: 0.9825\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9758 - val_loss: 0.0818 - val_accuracy: 0.9825\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9780 - val_loss: 0.0760 - val_accuracy: 0.9825\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9780 - val_loss: 0.0728 - val_accuracy: 0.9825\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9780 - val_loss: 0.0688 - val_accuracy: 0.9825\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9780 - val_loss: 0.0652 - val_accuracy: 0.9825\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9802 - val_loss: 0.0620 - val_accuracy: 0.9825\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9802 - val_loss: 0.0595 - val_accuracy: 0.9825\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9802 - val_loss: 0.0572 - val_accuracy: 0.9825\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9824 - val_loss: 0.0562 - val_accuracy: 0.9825\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9846 - val_loss: 0.0540 - val_accuracy: 0.9825\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0558 - accuracy: 0.9846 - val_loss: 0.0526 - val_accuracy: 0.9825\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9868 - val_loss: 0.0510 - val_accuracy: 0.9825\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9890 - val_loss: 0.0498 - val_accuracy: 0.9825\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0496 - accuracy: 0.9890 - val_loss: 0.0484 - val_accuracy: 0.9825\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9890 - val_loss: 0.0474 - val_accuracy: 0.9825\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9868 - val_loss: 0.0464 - val_accuracy: 0.9825\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9868 - val_loss: 0.0458 - val_accuracy: 0.9825\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9890 - val_loss: 0.0447 - val_accuracy: 0.9825\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0440 - val_accuracy: 0.9825\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9890 - val_loss: 0.0431 - val_accuracy: 0.9825\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0390 - accuracy: 0.9890 - val_loss: 0.0419 - val_accuracy: 0.9825\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9912 - val_loss: 0.0414 - val_accuracy: 0.9825\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.0405 - val_accuracy: 0.9825\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.0406 - val_accuracy: 0.9825\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.0402 - val_accuracy: 0.9825\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.0392 - val_accuracy: 0.9825\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0385 - val_accuracy: 0.9825\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 0.0378 - val_accuracy: 0.9825\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 0.9956 - val_loss: 0.0394 - val_accuracy: 0.9825\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9956 - val_loss: 0.0380 - val_accuracy: 0.9825\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9956 - val_loss: 0.0373 - val_accuracy: 0.9825\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0269 - accuracy: 0.9956 - val_loss: 0.0371 - val_accuracy: 0.9825\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9956 - val_loss: 0.0358 - val_accuracy: 0.9825\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9956 - val_loss: 0.0355 - val_accuracy: 0.9825\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9956 - val_loss: 0.0354 - val_accuracy: 0.9825\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9956 - val_loss: 0.0345 - val_accuracy: 0.9825\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9956 - val_loss: 0.0338 - val_accuracy: 0.9825\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 0.9956 - val_loss: 0.0335 - val_accuracy: 0.9825\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 0.9956 - val_loss: 0.0330 - val_accuracy: 0.9825\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9956 - val_loss: 0.0327 - val_accuracy: 0.9912\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 0.9956 - val_loss: 0.0323 - val_accuracy: 0.9825\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.0317 - val_accuracy: 0.9825\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9825\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.0310 - val_accuracy: 0.9825\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.0306 - val_accuracy: 0.9912\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0306 - val_accuracy: 0.9912\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.0301 - val_accuracy: 0.9912\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 0.0297 - val_accuracy: 0.9912\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0295 - val_accuracy: 0.9912\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0301 - val_accuracy: 0.9825\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0299 - val_accuracy: 0.9912\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0286 - val_accuracy: 0.9912\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0292 - val_accuracy: 0.9912\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 0.0276 - val_accuracy: 0.9912\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0268 - val_accuracy: 0.9912\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0270 - val_accuracy: 0.9912\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9978 - val_loss: 0.0269 - val_accuracy: 0.9912\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0269 - val_accuracy: 0.9912\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0268 - val_accuracy: 0.9912\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0267 - val_accuracy: 0.9912\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.0266 - val_accuracy: 0.9912\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0268 - val_accuracy: 0.9912\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0267 - val_accuracy: 0.9912\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0267 - val_accuracy: 0.9912\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9912\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0271 - val_accuracy: 0.9912\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9912\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9912\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9912\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9912\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9912\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9912\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9912\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9912\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9912\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0243 - val_accuracy: 0.9912\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(train_features, train_labels, validation_data=(test_features, test_labels), epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "`model.fit` returns a history object which contains the loss and accuracy of the model at each epoch. So now we can use this object to plot accuracy across time so as to get a better understanding of the model's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "With the model trained, we now use it to make predictions about the type of the tumor. We attach a softmax layer to convert the model's output to probabilities, which are easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model,\n",
    "                                         tf.keras.layers.Softmax()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We let the model predict the clarity of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = probability_model.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the first prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is an array of 2 numbers. They represent the model's \"confidence\" that the tumor type corresponds to each of the 2 different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Malignant'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_labels = ['Benign', 'Malignant']\n",
    "\n",
    "type_labels[np.argmax(predictions[0])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Performance\n",
    "\n",
    "To get an overview of the model's performance, we print the confusion matrix of the predicted labels. This shows us how many labels did the model classify correctly and how many did he miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0   1\n",
      "Actual           \n",
      "0          69   1\n",
      "1           0  44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = np.argmax(predictions, axis=1)\n",
    "predicted.shape\n",
    "\n",
    "confusion_matrix = pd.crosstab(test_labels, predicted, rownames=[\n",
    "                               'Actual'], colnames=['Predicted'])\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualise the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix = pd.crosstab(test_labels, predicted, rownames=[\n",
    "                               'Actual'], colnames=['Predicted'])\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.ticklabel_format(style='plain')\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We built a classifying deep neural network model to classify the tumor type using TensorFlow library. The model reached top accuracy of 99.12%. In the end we visualised the model's performance using the confusion matrix."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f8cf99212f81ad0c4765861267244807ee1c18364846cdce387b28994a977ba"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
